{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f418601f",
   "metadata": {},
   "source": [
    "In this space we will implement Principal Component Analysis to reduce complexity.\n",
    "We start by importing all libraries that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9414dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a50c64",
   "metadata": {},
   "source": [
    "We now load in our .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4f6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('simulated_health_wellness_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac196a1",
   "metadata": {},
   "source": [
    "Now that we have the dataset to work with, we set the features to be the data columns. We can now standardize the data columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b35e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.columns  \n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de23f434",
   "metadata": {},
   "source": [
    "We now have to set our amount of components for the PCA. We have the PCA ran on the scaled_data from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacfe1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2  \n",
    "pca = PCA(n_components=n_components)\n",
    "principal_components = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb39dc",
   "metadata": {},
   "source": [
    "We now have to create a DataFrame with the principal components. Inside of columns code is to automatically designate columns as PC(whatever number column), this serves to always add 1 to the next column over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d48c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n_components)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734e45d",
   "metadata": {},
   "source": [
    "At this point we want to see how well our model explains the total variance captured in the principal components. To do this we use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2df8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.23691549 0.22082517]\n"
     ]
    }
   ],
   "source": [
    "print(f'Explained variance ratio: {pca.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a1a07",
   "metadata": {},
   "source": [
    "We now want to save our PCA to a new .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7a397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df.to_csv('principal_components.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
